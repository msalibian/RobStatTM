---
title: "MM-Ridge-test"
author: "Matias Salibian-Barrera"
date: "September 13, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Comparing S and MM-Ridge implementations

Below I compare the implementations of the S-ridge estimator
that are present in the packages `mmlasso` and `pense`. In addition
I also look at the output of the MM-ridge estimator computed with 
the function `pense::mstep()` setting `alpha = 0`. 

### TL;DR
The main conclusions seem to be that

- `mmlasso::sridge()` and `pense::pense()` behave similarly enough (at least when `alpha = 0`), but are not identical, and can be rather different (see the repetition of the example below but with `n = 50` instead, for example);
- the residual scale returned by `mmlasso::sridge()` can be rather different from the one in `pense::pense()` (**Can this have an effect on the resulting PENSE-M we use in our simulations?**); and
- the function `pense::mstep()` returns yet another residual scale estimate, this doesn't seem to be documented.

## S-ridge in packages mmlasso and pense

<!-- Below is a comparison (aka "sanity check") between the implementations -->
<!-- of the S-ridge estimators in packages `mmlasso` and `pense`. In addition, -->
<!-- I also look at the output of the MM-ridge estimator computed with  -->
<!-- the function `pense::mstep()` setting `alpha = 0`.  -->

We first load the libraries and generate a simple synthetic data set:
```{r packages, message=FALSE, warning=FALSE}
library(pense)
library(mmlasso)
# simple synthetic example
n <- 100
p <- 20
set.seed(123)
x <- matrix(rnorm(n*p), n, p)
y <- as.vector( x %*% c(rep(2, 5), rep(0, p-5))) + rnorm(n, sd=.5)
```
We now use `mmlasso::sridge` and `pense::pense` (the latter with `alpha= 0`) to 
compute an S-ridge estimator.
```{r sridge}
# mmlasso S-ridge
a <- sridge(x=x, y=y, cualcv.S=5, numlam.S=30, niter.S=50, normin=0,
            denormout=0, alone=1, ncores=4)
# pense S-ridge 
b0 <- pense(X=x, y=y, alpha=0, standardize=TRUE, lambda=1e-9, initial='cold',
           options=pense_options(delta=a$delta))
```
Note that the optimal value of the penalization found by `mmlasso::sridge` is
`r a$lamda` but `pense::pense()` does not accept `lambda=0` as an argument, so 
I used `lambda = 1e-9` above. 

Also note that I did set `options=pense_options(delta=a$delta)` above to make sure
`pense::pense()` was optimizing the same M-scale as `mmlasso::sridge()`. This value
is adjusted internally, and for this example it was equal to `r a$delta`.

Although the estimated residual scales are somewhat different
(`r c(a$scale, b0$scale)`, for `sridge` and `pense`, respectively), the
regression estimators are similar:
```{r regr}
cbind(a$coef, as.vector(b0$coef[,1]))
```

We can now use `pense::mstep()` to do the M-step starting from the S-ridge
estimator as computed by `pense::pense()`:
```{r mmridge}
g <- mstep(b0, complete_grid=TRUE)
cbind(a$coef, as.vector(b0$coef[,1]), g$coefficients[,1])
```
This looks reasonable, however the scale estimators can be a bit different:
```{r sigmas}
c(a$scale, b0$scale, g$scale)
```
Just for the record, the optimal value of the penalization found in this M-step
was
```{r optlam}
g$lambda
```

## Nevertheless, things can be rather different sometimes

If we repeat the same experiment as above, but with `n = 50` instead of `n = 100`
we see that the two implementations of S-ridge can be rather different:
```{r round2, message=FALSE, warning=FALSE}
# another simple synthetic example
n <- 50
p <- 20
set.seed(123)
x <- matrix(rnorm(n*p), n, p)
y <- as.vector( x %*% c(rep(2, 5), rep(0, p-5))) + rnorm(n, sd=.5)
# mmlasso S-ridge
a <- sridge(x=x, y=y, cualcv.S=5, numlam.S=30, niter.S=50, normin=0,
            denormout=0, alone=1, ncores=4)
# pense S-ridge 
b0 <- pense(X=x, y=y, alpha=0, standardize=TRUE, lambda=1e-9, initial='cold',
           options=pense_options(delta=a$delta))
```
The optimal penalization from `sridge` is still `r a$lamda`. 
The scales and regression coefficients:
```{r scales2}
c(a$scale, b0$scale)
cbind(a$coef, as.vector(b0$coef[,1]))
```
Not surprisingly, the difference carries over to the M-step:
```{r mmridge2}
g <- mstep(b0, complete_grid=TRUE)
c(a$scale, b0$scale, g$scale)
cbind(a$coef, as.vector(b0$coef[,1]), g$coefficients[,1])
```


